{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import argparse\n",
    "import io\n",
    "import os\n",
    "from datetime import date\n",
    "# Imports the Google News api\n",
    "from newsapi import NewsApiClient\n",
    "\n",
    "# Imports the Google Cloud client library\n",
    "from google.cloud import language\n",
    "from google.cloud.language import enums\n",
    "from google.cloud.language import types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(text):\n",
    "    language_client = language.LanguageServiceClient.from_service_account_json('htn2019-f059d4b46f7d.json')\n",
    "    document = language.types.Document(content=text, type=language.enums.Document.Type.PLAIN_TEXT)\n",
    "    response = language_client.classify_text(document)\n",
    "    categories = response.categories\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    for category in categories:\n",
    "        categories = category.name.split(\"/\")\n",
    "        categories.pop(0)\n",
    "        for i in range(len(categories)):\n",
    "            result[categories[i]] = category.confidence\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Enter the original currency: \")\n",
    "# original = input()\n",
    "print(\"Enter the new currency: \")\n",
    "# return = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = 'CAD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Article Retrieval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsapi = NewsApiClient(api_key='a93fd9a824b848bca3436e761c5a0d4d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today().strftime(\"%Y/%m/%d\").replace(\"/\",\"-\")\n",
    "\n",
    "# grabbing articles\n",
    "all_articles = newsapi.get_everything(q=original, from_param='2019-08-15', to=today, language='en', sort_by='relevancy')\n",
    "articles = all_articles['articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_articles = []\n",
    "\n",
    "# creating new article object\n",
    "for article in articles:\n",
    "    info = str(article['title']) + \" \" + str(article['description']) + \" \" + str(article['content'])\n",
    "    classifications = classify(info)\n",
    "    print(classifications)\n",
    "    print()\n",
    "#     print(classifications)\n",
    "    if classifications:\n",
    "        individual_article = {}\n",
    "        # just the date\n",
    "        # print(article['publishedAt'][:10])\n",
    "        individual_article['date'] = article['publishedAt']\n",
    "\n",
    "        info = info.replace(\"'\",\"\") \n",
    "        individual_article['text'] = info\n",
    "\n",
    "        formatted_articles.append(individual_article)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis (Tone Analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = language.LanguageServiceClient.from_service_account_json('htn2019-f059d4b46f7d.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_analyzed_articles = []\n",
    "\n",
    "# The text to analyze\n",
    "for i in range(len(formatted_articles)):\n",
    "    analyzed_article = {}\n",
    "    article = formatted_articles[i]\n",
    "    text = article['text']\n",
    "    \n",
    "    document = types.Document(content = text, type = enums.Document.Type.PLAIN_TEXT)\n",
    "    \n",
    "    # Detects the sentiment of the text\n",
    "    sentiment = client.analyze_sentiment(document=document).document_sentiment\n",
    "    \n",
    "    analyzed_article['date'] = article['date']\n",
    "    analyzed_article['score'] = sentiment.score\n",
    "    analyzed_article['magnitude'] = sentiment.magnitude\n",
    "    \n",
    "    tone_analyzed_articles.append(analyzed_article)\n",
    "\n",
    "print(json.dumps(tone_analyzed_articles, indent=4, sort_keys=True))\n",
    "\n",
    "#     print('Text: {}'.format(text))\n",
    "#     print('Sentiment: {}, {}'.format(, sentiment.magnitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
