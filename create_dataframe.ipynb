{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keys import keys\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import io\n",
    "import os\n",
    "from datetime import date\n",
    "\n",
    "# XE api\n",
    "from xecd_rates_client import XecdClient\n",
    "\n",
    "# Google News api\n",
    "from newsapi import NewsApiClient\n",
    "\n",
    "# Google Cloud client library api\n",
    "from google.cloud import language\n",
    "from google.cloud.language import enums\n",
    "from google.cloud.language import types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class create_df:\n",
    "    def __init__(self, cur_original, cur_new, news_api_key, json_google_cloud, xecd_client):\n",
    "        self.today = date.today().strftime(\"%Y/%m/%d\").replace(\"/\",\"-\")\n",
    "        self.original = cur_original\n",
    "        self.new = cur_new\n",
    "        self.newsapi = NewsApiClient(api_key=news_api_key)\n",
    "        self.client = language.LanguageServiceClient.from_service_account_json(json_google_cloud)\n",
    "        self.xecd = xecd_client\n",
    "        self.approved_classifications = [\n",
    "            'Finance',\n",
    "            'Business',\n",
    "            'Politics',\n",
    "            'Jobs & Education',\n",
    "            'Business News',\n",
    "            'Business & Industrial',\n",
    "        ]\n",
    "        \n",
    "        \n",
    "    # classify text into categories   \n",
    "    def __classify(self, text):\n",
    "        client = self.client\n",
    "        document = language.types.Document(content=text, type=language.enums.Document.Type.PLAIN_TEXT)\n",
    "        response = client.classify_text(document)\n",
    "        categories = response.categories\n",
    "\n",
    "        result = []\n",
    "\n",
    "        for category in categories:\n",
    "            categories = category.name.split(\"/\")\n",
    "            categories.pop(0)\n",
    "            for i in range(len(categories)):\n",
    "                result.append(categories[i])\n",
    "        return result\n",
    "    \n",
    "    def __getRate(self, date, fromCur, toCur):\n",
    "        xecd = self.xecd\n",
    "        rateResult = xecd.historic_rate(date, \"12:00\", fromCur, toCur, 1)\n",
    "        rateObj={}\n",
    "        rateObj['date'] = rateResult['timestamp'][:10]\n",
    "        rateObj['rate'] = rateResult['to'][0]['mid']\n",
    "        return rateObj['rate']\n",
    "    \n",
    "    \n",
    "    # retrieve articles from google news api\n",
    "    def __retrieve_articles(self):\n",
    "        today = self.today\n",
    "        # grabbing articles\n",
    "        newsapi = self.newsapi\n",
    "        \n",
    "        all_articles = newsapi.get_everything(q=self.original, from_param='2019-08-15', to=today, language='en', sort_by='relevancy')\n",
    "        articles = all_articles['articles']\n",
    "        \n",
    "        formatted_articles = []\n",
    "\n",
    "        # creating new article object\n",
    "        for article in articles:\n",
    "            info = str(article['title']) + \" \" + str(article['description']) + \" \" + str(article['content'])\n",
    "            classifications = self.__classify(info)\n",
    "            if len(set(classifications).intersection(set(self.approved_classifications))) != 0:\n",
    "                individual_article = {}\n",
    "                individual_article['date'] = article['publishedAt'][:10]\n",
    "\n",
    "                info = info.replace(\"'\",\"\") \n",
    "                individual_article['text'] = info\n",
    "\n",
    "                formatted_articles.append(individual_article)\n",
    "                \n",
    "        self.formatted_articles = formatted_articles\n",
    "#         print(json.dumps(self.formatted_articles, indent=4, sort_keys=True))\n",
    "        return\n",
    "    \n",
    "    \n",
    "    # Sentiment analysis using google cloud\n",
    "    def __sentiment_analysis(self):\n",
    "        client = self.client\n",
    "        tone_analyzed_articles = []\n",
    "        formatted_articles = self.formatted_articles.copy()\n",
    "\n",
    "        # The text to analyze\n",
    "        for i in range(len(formatted_articles)):\n",
    "            analyzed_article = {}\n",
    "            article = formatted_articles[i]\n",
    "            text = article['text']\n",
    "\n",
    "            document = types.Document(content = text, type = enums.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "            # Detects the sentiment of the text\n",
    "            sentiment = client.analyze_sentiment(document=document).document_sentiment\n",
    "            \n",
    "            # Gets currency rate\n",
    "            rate = self.__getRate(article['date'], self.original, self.new)\n",
    "            analyzed_article['date'] = article['date']\n",
    "            analyzed_article['score'] = sentiment.score\n",
    "            analyzed_article[self.original + \" to \" + self.new + \" Rate\"] = rate\n",
    "\n",
    "\n",
    "            tone_analyzed_articles.append(analyzed_article)\n",
    "\n",
    "        print(json.dumps(tone_analyzed_articles, indent=4, sort_keys=True))        \n",
    "        \n",
    "        return df\n",
    "        \n",
    "        \n",
    "    def __dump_df(self, df):\n",
    "        df.to_csv(\"data/From \" + self.original + \" to \" + self.new)\n",
    "        \n",
    "    def df_append(self):\n",
    "        self.__retrieve_articles()\n",
    "        df = self.__sentiment_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_api_key = keys['news']\n",
    "json_google_cloud = keys['json_google_cloud']\n",
    "xecd_client = keys['xe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Enter the original currency: \")\n",
    "# cur_original = input()\n",
    "print(\"Enter the new currency: \")\n",
    "# cur_return = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_original = 'CAD'\n",
    "cur_return = 'USD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_df(cur_original, cur_return, news_api_key, json_google_cloud, xecd_client)\n",
    "df.df_append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
